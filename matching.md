### Matching
- (CVPR'21') LoFTR: Detector-Free Local Feature Matching with Transformers, [[Paper]](https://arxiv.org/abs/2104.00680), [[Code]](https://zju3dv.github.io/loftr/)
- (arXiv 2022.02) Local Feature Matching with Transformers for low-end devices, [[Paper]](https://arxiv.org/pdf/2202.00770.pdf), [[Code]](https://github.com/Kolkir/Coarse_LoFTR_TRT)
- (arXiv 2022.02) CATs++: Boosting Cost Aggregation with Convolutions and Transformers, [[Paper]](https://arxiv.org/pdf/2202.06817.pdf), [[Code]](https://github.com/SunghwanHong/Cost-Aggregation-transformers)
- (arXiv 2022.03) MatchFormer: Interleaving Attention in Transformers for Feature Matching, [[Paper]](https://arxiv.org/pdf/2203.09645.pdf), [[Code]](https://github.com/jamycheung/MatchFormer)
- (arXiv 2022.05) TransforMatcher: Match-to-Match Attention for Semantic Correspondence, [[Paper]](https://arxiv.org/pdf/2205.11634.pdf), [[Code]](http://cvlab.postech.ac.kr/research/TransforMatcher)
- (arXiv 2022.07) Deep Laparoscopic Stereo Matching with Transformers, [[Paper]](https://arxiv.org/pdf/2207.12152.pdf)
- (arXiv 2022.08) ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer, [[Paper]](https://arxiv.org/pdf/2208.14201.pdf), [[Project]](https://aspanformer.github.io/)
- (arXiv 2023.01) DeepMatcher: A Deep Transformer-based Network for Robust and Accurate Local Feature Matching, [[Paper]](https://arxiv.org/pdf/2301.02993.pdf), [[Code]](https://github.com/XT-1997/DeepMatcher)
- (arXiv 2023.03) ParaFormer: Parallel Attention Transformer for Efficient Feature Matching, [[Paper]](https://arxiv.org/pdf/2303.00941.pdf)
- (arXiv 2023.03) Improving Transformer-based Image Matching by Cascaded Capturing Spatially Informative Keypoints, [[Paper]](https://arxiv.org/pdf/2303.02885.pdf)
- (arXiv 2023.03) Adaptive Spot-Guided Transformer for Consistent Local Feature Matching, [[Paper]](https://arxiv.org/pdf/2303.16624.pdf), [[Code]](https://astr2023.github.io/)
- (arXiv 2023.05) AMatFormer: Efficient Feature Matching via Anchor Matching Transformer, [[Paper]](https://arxiv.org/pdf/2305.19205.pdf)
- (arXiv 2023.08) Multi-scale Alternated Attention Transformer for Generalized Stereo Matching, [[Paper]](https://arxiv.org/pdf/2308.03048.pdf)
- (arXiv 2023.10) FMRT: Learning Accurate Feature Matching with Reconciliatory Transformer, [[Paper]](https://arxiv.org/pdf/2310.13605.pdf)
- (arXiv 2023.11) LGFCTR: Local and Global Feature Convolutional Transformer for Image Matching, [[Paper]](https://arxiv.org/pdf/2311.17571.pdf), [[Code]](https://github.com/zwh0527/LGFCTR)
- (arXiv 2023.12) Latent Space Editing in Transformer-Based Flow Matching, [[Paper]](https://arxiv.org/pdf/2312.10825.pdf), [[Code]](https://taohu.me/lfm/)
- (arXiv 2024.04) IFViT: Interpretable Fixed-Length Representation for Fingerprint Matching via Vision Transformer, [[Paper]](https://arxiv.org/pdf/2404.08237.pdf)
- (arXiv 2024.04) XoFTR: Cross-modal Feature Matching Transformer, [[Paper]](https://arxiv.org/pdf/2404.09692.pdf), [[Code]](https://github.com/OnderT/XoFTR)
- (arXiv 2024.05) A Light-weight Transformer-based Self-supervised Matching Network for Heterogeneous Images, [[Paper]](https://arxiv.org/pdf/2404.19311.pdf),[[Code]](https://github.com/NUST-Machine- Intelligence-Laboratory/LTFormer)
- (arXiv 2024.05) TP3M: Transformer-based Pseudo 3D Image Matching with Reference, [[Paper]](https://arxiv.org/pdf/2405.08434.pdf)
- (arXiv 2024.06) CorrMAE: Pre-training Correspondence Transformers with Masked Autoencoder, [[Paper]](https://arxiv.org/pdf/2409.02545.pdf)
