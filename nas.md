### NAS
- (CVPR'21) HR-NAS: Searching Efficient High-Resolution Neural Architectures with Lightweight Transformers, [[Paper]](https://arxiv.org/pdf/2106.06560.pdf), [[Code]](https://github.com/dingmyu/HR-NAS)
- (arXiv.2021.02) Towards Accurate and Compact Architectures via Neural Architecture Transformer, [[Paper]](https://arxiv.org/pdf/2102.10301.pdf)
- (arXiv.2021.03) BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search, [[Paper]](https://arxiv.org/abs/2103.12424), [[Code]](https://github.com/changlin31/BossNAS)
- (arXiv.2021.06) Vision Transformer Architecture Search, [[Paper]](https://arxiv.org/pdf/2106.13700.pdf), [[Code]](https://github.com/xiusu/ViTAS)
- (arXiv.2021.07) AutoFormer: Searching Transformers for Visual Recognition, [[Paper]](https://arxiv.org/pdf/2107.00651.pdf), [[Code]](https://github.com/microsoft/AutoML)
- (arXiv.2021.07) GLiT: Neural Architecture Search for Global and Local Image Transformer, [[Paper]](https://arxiv.org/pdf/2107.02960.pdf)
- (arXiv.2021.09) Searching for Efficient Multi-Stage Vision Transformers, [[Paper]](https://arxiv.org/pdf/2109.00642.pdf)
- (arXiv.2021.10) UniNet: Unified Architecture Search with Convolution, Transformer, and MLP, [[Paper]](https://arxiv.org/pdf/2110.04035.pdf)
- (arXiv.2021.11) Searching the Search Space of Vision Transformer, [[Paper]](https://arxiv.org/pdf/2111.14725.pdf), [[Code]](https://github.com/microsoft/Cream)
- (arXiv.2022.01) Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space, [[Paper]](https://arxiv.org/pdf/2201.00814.pdf)
- (arXiv.2022.03) Vision Transformer with Convolutions Architecture Search, [[Paper]](https://arxiv.org/pdf/2203.10435.pdf)
- (arXiv.2022.03) Training-free Transformer Architecture Search, [[Paper]](https://arxiv.org/pdf/2203.12217.pdf)
- (arXiv.2022.06) Neural Prompt Search, [[Paper]](https://arxiv.org/pdf/2206.04673.pdf)
- (arXiv.2022.07) UniNet: Unified Architecture Search with Convolution, Transformer, and MLP, [[Paper]](https://arxiv.org/pdf/2207.05420.pdf), [[Code]](https://github.com/Sense-X/UniNet)
- (arXiv.2022.09) NasHD: Efficient ViT Architecture Performance Ranking using Hyperdimensional Computing, [[Paper]](https://arxiv.org/pdf/2209.11356.pdf)
- (arXiv.2022.11) NAR-Former: Neural Architecture Representation Learning towards Holistic Attributes Prediction, [[Paper]](https://arxiv.org/pdf/2211.08024.pdf)
- (arXiv 2023.03) HyT-NAS: Hybrid Transformers Neural Architecture Search for Edge Devices, [[Paper]](https://arxiv.org/pdf/2303.04440.pdf), [[Code]](https://anonymous.4open.science/r/HyT-NAS-Search-Algorithm-A864/README.md)
- (arXiv 2023.07) AutoST: Training-free Neural Architecture Search for Spiking Transformers, [[Paper]](https://arxiv.org/pdf/2307.00293.pdf)
- (arXiv 2023.08) TurboViT: Generating Fast Vision Transformers via Generative Architecture Search, [[Paper]](https://arxiv.org/pdf/2308.11421.pdf)
- (arXiv 2023.11) FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer, [[Paper]](https://arxiv.org/pdf/2311.03912.pdf), [[Code]](https://github.com/shadowpa0327/FLORA)
- (arXiv 2023.11) TVT: Training-Free Vision Transformer Search on Tiny Datasets, [[Paper]](https://arxiv.org/pdf/2311.14337.pdf)
- (arXiv 2023.12) Auto-Prox: Training-Free Vision Transformer Architecture Search via Automatic Proxy Discovery, [[Paper]](https://arxiv.org/pdf/2312.09059.pdf)
- (arXiv.2024.03) Once for Both: Single Stage of Importance and Sparsity Search for Vision Transformer Compression, [[Paper]](https://arxiv.org/pdf/2403.15835.pdf)
- (arXiv.2024.05) When Training-Free NAS Meets Vision Transformer: A Neural Tangent Kernel Perspective, [[Paper]](https://arxiv.org/pdf/2405.04536.pdf)
- (arXiv.2024.07) HyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark and Analysis, [[Paper]](https://arxiv.org/pdf/2407.16269.pdf)
- (arXiv.2024.07) Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers, [[Paper]](https://arxiv.org/pdf/2407.18175.pdf)
