### In-painting
- (ECCV'20) Learning Joint Spatial-Temporal Transformations for Video Inpainting, [[Paper]](https://arxiv.org/abs/2007.10247), [[Code]](https://github.com/researchmm/STTN)
- (arXiv 2021.04) Aggregated Contextual Transformations for High-Resolution Image Inpainting, [[Paper]](https://arxiv.org/abs/2104.01431), [[Code]](https://github.com/researchmm/AOT-GAN-for-Inpainting)
- (arXiv 2021.04) Decoupled Spatial-Temporal Transformer for Video Inpainting, [[Paper]](https://arxiv.org/pdf/2112.08275.pdf), [[Code]](https://github.com/wjf5203/SeqFormer)
- (arXiv 2022.03) Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding, [[Paper]](https://arxiv.org/pdf/2203.00867.pdf), [[Code]](https://github.com/DQiaole/ZITS_inpainting)
- (arXiv 2022.03) MAT: Mask-Aware Transformer for Large Hole Image Inpainting, [[Paper]](https://arxiv.org/pdf/2203.15270.pdf), [[Code]](https://github.com/fenglinglwb/MAT)
- (arXiv 2022.05) Reduce Information Loss in Transformers for Pluralistic Image Inpainting, [[Paper]](https://arxiv.org/pdf/2205.05076.pdf)
- (arXiv 2022.08) Flow-Guided Transformer for Video Inpainting, [[Paper]](https://arxiv.org/pdf/2208.06768.pdf), [[Code]](https://github.com/hitachinsk/FGT)
- (arXiv 2022.09) DeViT: Deformed Vision Transformers in Video Inpainting, [[Paper]](https://arxiv.org/pdf/2209.13925.pdf)
- (arXiv 2022.10) TPFNet: A Novel Text In-painting Transformer for Text Removal, [[Paper]](https://arxiv.org/pdf/2210.14461.pdf), [[Code]](https://github.com/CandleLabAI/TPFNet)
- (arXiv 2023.01) Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting, [[Paper]](https://arxiv.org/pdf/2301.10048.pdf)
- (arXiv 2023.05) T-former: An Efficient Transformer for Image Inpainting, [[Paper]](https://arxiv.org/pdf/2305.07239.pdf), [[Code]](https://github.com/dengyecode/T-former_image_inpainting)
- (arXiv 2023.06) TransRef: Multi-Scale Reference Embedding Transformer for Reference-Guided Image Inpainting, [[Paper]](https://arxiv.org/pdf/2306.11528.pdf), [[Code]](https://github.com/Cameltr/TransRef)
- (arXiv 2023.07) Deficiency-Aware Masked Transformer for Video Inpainting, [[Paper]](https://arxiv.org/pdf/2307.08629.pdf), [[Code]](http://github.com/yeates/DMT)
- (arXiv 2023.09) ProPainter: Improving Propagation and Transformer for Video Inpainting, [[Paper]](https://arxiv.org/pdf/2309.03897.pdf), [[Code]](https://github.com/sczhou/ProPainter)
- (arXiv 2024.01) Federated Class-Incremental Learning with Prototype Guided Transformer, [[Paper]](https://arxiv.org/pdf/2401.02094.pdf)
- (arXiv 2024.02) HINT: High-quality INPainting Transformer with Mask-Aware Encoding and Enhanced Attention, [[Paper]](https://arxiv.org/pdf/2402.14185.pdf), [[Code]](https://github.com/ChrisChen1023/HINT)
- (arXiv 2024.03) Towards Online Real-Time Memory-based Video Inpainting Transformers, [[Paper]](https://arxiv.org/pdf/2403.16161.pdf), [[Code]](https://github.com/ChrisChen1023/HINT)
- (arXiv 2024.04) Raformer: Redundancy-Aware Transformer for Video Wire Inpainting, [[Paper]](https://arxiv.org/pdf/2404.15802.pdf), [[Code]](https://github.com/Suyimu/WRV2)
- (arXiv 2024.07) Transformer-based Image and Video Inpainting: Current Challenges and Future Directions, [[Paper]](https://arxiv.org/pdf/2407.00226.pdf)
- (arXiv 2024.07) MxT: Mamba x Transformer for Image Inpainting, [[Paper]](https://arxiv.org/pdf/2407.16126.pdf)
