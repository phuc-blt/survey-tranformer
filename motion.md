### Motion
- (arXiv 2021.03) Single-Shot Motion Completion with Transformer, [[Paper]](https://arxiv.org/pdf/2103.00776.pdf), [[Code]](https://github.com/FuxiCV/SSMCT)
- (arXiv 2021.03) DanceNet3D: Music Based Dance Generation with Parametric Motion Transformer, [[Paper]](https://arxiv.org/pdf/2103.10206.pdf)
- (arXiv 2021.03) Multimodal Motion Prediction with Stacked Transformers, [[Paper]](https://arxiv.org/pdf/2103.11624.pdf), [[Code]](https://github.com/decisionforce/mmTransformer)
- (arXiv 2021.04) Action-Conditioned 3D Human Motion Synthesis with Transformer VAE, [[Paper]](https://arxiv.org/abs/2104.05670)
- (arXiv 2021.10) AniFormer: Data-driven 3D Animation with Transformer, [[Paper]](https://arxiv.org/pdf/2110.10533.pdf), [[Code]](https://github.com/mikecheninoulu/AniFormer)
- (arXiv 2021.11) Multi-Person 3D Motion Prediction with Multi-Range Transformers, [[Paper]](https://arxiv.org/pdf/2111.12073.pdf), [[Code]](https://jiashunwang.github.io/MRT/)
- (arXiv 2022.03) ActFormer: A GAN Transformer Framework towards General Action-Conditioned 3D Human Motion Generation, [[Paper]](https://arxiv.org/pdf/2203.07706.pdf)
- (arXiv 2022.03) Transformer Inertial Poser: Attention-based Real-time Human Motion Reconstruction from Sparse IMUs, [[Paper]](https://arxiv.org/pdf/2203.15720.pdf)
- (arXiv 2022.03) Spatial-Temporal Parallel Transformer for Arm-Hand Dynamic Estimation, [[Paper]](https://arxiv.org/pdf/2203.16202.pdf)
- (arXiv 2022.04) HiT-DVAE: Human Motion Generation via Hierarchical Transformer Dynamical VAE, [[Paper]](https://arxiv.org/pdf/2204.01565.pdf)
- (arXiv 2022.07) TENET: Transformer Encoding Network for Effective Temporal Flow on Motion Prediction, [[Paper]](https://arxiv.org/pdf/2207.00170.pdf)
- (arXiv 2022.08) SoMoFormer: Social-Aware Motion Transformer for Multi-Person Motion Prediction, [[Paper]](https://arxiv.org/pdf/2208.09224.pdf)
- (arXiv 2022.09) Motion Transformer with Global Intention Localization and Local Movement Refinement, [[Paper]](https://arxiv.org/pdf/2209.13508.pdf), [[Code]](https://github.com/sshaoshuai/MTR)
- (arXiv 2022.09) NEURAL MARIONETTE: A Transformer-based Multi-action Human Motion Synthesis System, [[Paper]](https://arxiv.org/pdf/2209.13204.pdf), [[Project]](https://wjohnnyw.github.io/blog/tag2motion/)
- (arXiv 2022.09) Motion Transformer for Unsupervised Image Animation, [[Paper]](https://arxiv.org/pdf/2209.14024.pdf), [[Code]](https://github.com/JialeTao/MoTrans)
- (arXiv 2022.11) Blur Interpolation Transformer for Real-World Motion from Blur, [[Paper]](https://arxiv.org/pdf/2211.11423.pdf)
- (arXiv 2022.12) Transformer-Based Learned Optimization, [[Paper]](https://arxiv.org/pdf/2212.01055.pdf)
- (arXiv 2023.01) Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification, [[Paper]](https://arxiv.org/pdf/2301.08125.pdf)
- (arXiv 2023.02) Robust Human Motion Forecasting using Transformer-based Model, [[Paper]](https://arxiv.org/pdf/2302.08274.pdf)
- (arXiv 2023.02) STB-VMM: Swin Transformer Based Video Motion Magnification, [[Paper]](https://arxiv.org/pdf/2302.10001.pdf)
- (arXiv 2023.02) Human MotionFormer: Transferring Human Motions with Vision Transformers, [[Paper]](https://arxiv.org/pdf/2302.11306.pdf), [[Project]](https://github.com/KumapowerLIU/Human-MotionFormer)
- (arXiv 2023.02) Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase, [[Paper]](https://arxiv.org/pdf/2303.01685.pdf)
- (arXiv 2023.03) SPOTR: Spatio-temporal Pose Transformers for Human Motion Prediction, [[Paper]](https://arxiv.org/pdf/2303.06277.pdf)
- (arXiv 2023.04) BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation, [[Paper]](https://arxiv.org/pdf/2304.02225.pdf), [[Code]](https://github.com/JunHeum/BiFormer)
- (arXiv 2023.05) XFormer: Fast and Accurate Monocular 3D Body Capture, [[Paper]](https://arxiv.org/pdf/2305.11101.pdf)
- (arXiv 2023.05) Imitating Task and Motion Planning with Visuomotor Transformers, [[Paper]](https://arxiv.org/pdf/2305.16309.pdf), [[Code]](https://mihdalal.github.io/optimus/)
- (arXiv 2023.06) PGformer: Proxy-Bridged Game Transformer for Multi-Person Extremely Interactive Motion Prediction, [[Paper]](https://arxiv.org/pdf/2306.03374.pdf)
- (arXiv 2023.06) ModeT: Learning Deformable Image Registration via Motion Decomposition Transformer, [[Paper]](https://arxiv.org/pdf/2306.05688.pdf), [[Code]](https://github.com/ZAX130/SmileCode)
- (arXiv 2023.07) TransFusion: A Practical and Effective Transformer-based Diffusion Model for 3D Human Motion Prediction, [[Paper]](https://arxiv.org/pdf/2307.16106.pdf)
- (arXiv 2023.08) Joint-Relation Transformer for Multi-Person Motion Prediction, [[Paper]](https://arxiv.org/pdf/2308.04808.pdf), [[Code]](https://github.com/MediaBrain-SJTU/JRTransformer)
- (arXiv 2023.08) A Unified Masked Autoencoder with Patchified Skeletons for Motion Synthesis, [[Paper]](https://arxiv.org/pdf/2308.07301.pdf), [[Code]](https://github.com/Sadegh28/ATR)
- (arXiv 2023.10) Real-Time Motion Prediction via Heterogeneous Polyline Transformer with Relative Pose Encoding, [[Paper]](https://arxiv.org/pdf/2310.12970.pdf), [[Code]](https://github.com/zhejz/HPTR)
- (arXiv 2023.11) Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement, [[Paper]](https://arxiv.org/pdf/2311.16495.pdf)
- (arXiv 2023.12) MGTR: Multi-Granular Transformer for Motion Prediction with LiDAR, [[Paper]](https://arxiv.org/pdf/2312.02409.pdf), [[Code]](https://waymo.com/open/challenges/2023/motion-prediction/)
- (arXiv 2023.12) EulerMormer: Robust Eulerian Motion Magnification via Dynamic Filtering within Transformer, [[Paper]](https://arxiv.org/pdf/2312.04152.pdf), [[Code]](https://github.com/VUT-HFUT/EulerMormer)
- (arXiv 2023.12) Sign Language Production with Latent Motion Transformer, [[Paper]](https://arxiv.org/pdf/2312.12917.pdf)
- (arXiv 2024.01) AdvMT: Adversarial Motion Transformer for Long-term Human Motion Prediction, [[Paper]](https://arxiv.org/pdf/2401.05018.pdf)
- (arXiv 2024.04) Neuromorphic Vision-based Motion Segmentation with Graph Transformer Neural Network, [[Paper]](https://arxiv.org/pdf/2404.10940.pdf)
- (arXiv 2024.04) Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches, [[Paper]](https://arxiv.org/pdf/2405.04771.pdf)
- (arXiv 2024.06) Prototypical Transformer as Unified Motion Learners, [[Paper]](https://arxiv.org/pdf/2406.01559), [[Code]](https://github.com/Alvin0629/ProtoFormer)
- (arXiv 2024.07) FootBots: A Transformer-based Architecture for Motion Prediction in Soccer, [[Paper]](https://arxiv.org/pdf/2406.19852), [[Code]](https://github.com/Alvin0629/ProtoFormer)
- (arXiv 2024.07) InfiniMotion: Mamba Boosts Memory in Transformer for Arbitrary Long Motion Generation, [[Paper]](https://arxiv.org/pdf/2407.10061)
- (arXiv 2024.08) Pedestrian Motion Prediction Using Transformer-based Behavior Clustering and Data-Driven Reachability Analysis, [[Paper]](https://arxiv.org/pdf/2408.15250)
- (arXiv 2024.09) Transformer with Controlled Attention for Synchronous Motion Captioning, [[Paper]](https://arxiv.org/pdf/2409.09177), [[Code]](https://github.com/rd20karim/Synch-Transformer)
- (arXiv 2024.10) DART: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control, [[Paper]](https://arxiv.org/pdf/2410.05260), [[Code]](https://zkf1997.github.io/DART/)
