### Bird's-Eye-View
- (arXiv 2022.03) BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers, [[Paper]](https://arxiv.org/pdf/2203.17270.pdf), [[Code]](https://github.com/zhiqi-li/BEVFormer)
- (arXiv 2022.05) ViT-BEVSeg: A Hierarchical Transformer Network for Monocular Birds-Eye-View Segmentation, [[Paper]](https://arxiv.org/pdf/2205.15667.pdf), [[Code]](https://github.com/robotvisionmu/ViT-BEVSeg)
- (arXiv 2022.06) PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images, [[Paper]](https://arxiv.org/pdf/2206.01256.pdf)
- (arXiv 2022.06) Efficient and Robust 2D-to-BEV Representation Learning via Geometry-guided Kernel Transformer, [[Paper]](https://arxiv.org/pdf/2206.04584.pdf), [[Code]](https://github.com/hustvl/GKT)
- (arXiv 2022.06) PolarFormer: Multi-camera 3D Object Detection with Polar Transformer, [[Paper]](https://arxiv.org/pdf/2206.15398.pdf), [[Code]](https://github.com/fudan-zvg/PolarFormer)
- (arXiv 2022.07) CoBEVT: Cooperative Bird's Eye View ation with Sparse Transformers, [[Paper]](https://arxiv.org/pdf/2207.02202.pdf)
- (arXiv 2022.07) UniFormer: Unified Multi-view Fusion Transformer for Spatial-Temporal Representation in Bird's-Eye-View, [[Paper]](https://arxiv.org/pdf/2207.08536.pdf)
- (arXiv 2022.09) A Dual-Cycled Cross-View Transformer Network for Unified Road Layout Estimation and 3D Object Detection in the Bird's-Eye-View, [[Paper]](https://arxiv.org/pdf/2209.08844.pdf)
- (arXiv 2022.09) BEV-LGKD: A Unified LiDAR-Guided Knowledge Distillation Framework for BEV 3D Object Detection, [[Paper]](https://arxiv.org/pdf/2212.00623.pdf)
- (arXiv 2023.02) DA-BEV: Depth Aware BEV Transformer for 3D Object Detection, [[Paper]](https://arxiv.org/pdf/2302.13002.pdf)
- (arXiv 2023.03) TBP-Former: Learning Temporal Bird's-Eye-View Pyramid for Joint Perception and Prediction in Vision-Centric Autonomous Driving, [[Paper]](https://arxiv.org/pdf/2303.09998.pdf), [[Code]](https://github.com/MediaBrain-SJTU/TBP-Former)
- (arXiv 2023.04) VoxelFormer: Bird's-Eye-View Feature Generation based on Dual-view Attention for Multi-view 3D Object Detection, [[Paper]](https://arxiv.org/pdf/2304.01054.pdf), [[Code]](https://github.com/Lizhuoling/VoxelFormer-public.git)
- (arXiv 2023.04) FedBEVT: Federated Learning Bird's Eye View Perception Transformer in Road Traffic Systems, [[Paper]](https://arxiv.org/pdf/2304.01534.pdf)
- (arXiv 2023.04) A Cross-Scale Hierarchical Transformer with Correspondence-Augmented Attention for inferring Bird's-Eye-View ation, [[Paper]](https://arxiv.org/pdf/2304.03650.pdf)
- (arXiv 2023.06) OCBEV: Object-Centric BEV Transformer for Multi-View 3D Object Detection, [[Paper]](https://arxiv.org/pdf/2306.01738.pdf)
- (arXiv 2023.06) An Efficient Transformer for Simultaneous Learning of BEV and Lane Representations in 3D Lane Detection, [[Paper]](https://arxiv.org/pdf/2306.04927.pdf)
- (arXiv 2023.07) HeightFormer: Explicit Height Modeling without Extra Data for Camera-only 3D Object Detection in Bird鈥檚 Eye View, [[Paper]](https://arxiv.org/pdf/2307.13510.pdf)
- (arXiv 2023.08) UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation, [[Paper]](https://arxiv.org/pdf/2308.07732.pdf), [[Code]](https://github.com/Haiyang-W/UniTR)
- (arXiv 2023.09) FusionFormer: A Multi-sensory Fusion in Bird's-Eye-View and Temporal Consistent Transformer for 3D Objection, [[Paper]](https://arxiv.org/pdf/2309.05257.pdf)
- (arXiv 2023.10) Towards Generalizable Multi-Camera 3D Object Detection via Perspective Debiasing, [[Paper]](https://arxiv.org/pdf/2310.11346.pdf)
- (arXiv 2023.12) Towards Efficient 3D Object Detection in Bird's-Eye-View Space for Autonomous Driving: A Convolutional-Only Approach, [[Paper]](https://arxiv.org/pdf/2312.00633.pdf)
- (arXiv 2023.12) BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection, [[Paper]](https://arxiv.org/pdf/2312.01696.pdf)
- (arXiv 2023.12) COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy Prediction, [[Paper]](https://arxiv.org/pdf/2312.01919.pdf)
- (arXiv 2023.12) Learned Fusion: 3D Object Detection using Calibration-Free Transformer Feature Fusion, [[Paper]](https://arxiv.org/pdf/2312.09082.pdf)
- (arXiv 2023.12) Diffusion-Based Particle-DETR for BEV Perception, [[Paper]](https://arxiv.org/pdf/2312.11578.pdf)
- (arXiv 2023.12) Lift-Attend-Splat: Bird's-eye-view camera-lidar fusion using transformers, [[Paper]](https://arxiv.org/pdf/2312.14919.pdf)
- (arXiv 2024.01) WidthFormer: Toward Efficient Transformer-based BEV View Transformation, [[Paper]](https://arxiv.org/pdf/2401.03836.pdf), [[Code]](https://github.com/ChenhongyiYang/WidthFormer)
- (arXiv 2024.02) OccTransformer: Improving BEVFormer for 3D camera-only occupancy prediction, [[Paper]](https://arxiv.org/pdf/2402.18140.pdf)
- (arXiv 2024.03) CLIP-BEVFormer: Enhancing Multi-View Image-Based BEV Detector with Ground Truth Flow,  [[Paper]](https://arxiv.org/pdf/2403.08919.pdf)
- (arXiv 2024.07) BEVWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space,  [[Paper]](https://arxiv.org/pdf/2407.05679.pdf), [[Code]](https://github.com/zympsyche/BevWorld)
- (arXiv 2024.07) CarFormer: Self-Driving with Learned Object-Centric Representations,  [[Paper]](https://arxiv.org/pdf/2407.15843.pdf), [[Code]](https://github.com/Shamdan17/CarFormer)
- (arXiv 2024.07) RayFormer: Improving Query-Based Multi-Camera 3D Object Detection via Ray-Centric Strategies,  [[Paper]](https://arxiv.org/pdf/2407.14923.pdf)
- (arXiv 2024.09) CASPFormer: Trajectory Prediction from BEV Images with Deformable Attention,  [[Paper]](https://arxiv.org/pdf/2409.17790.pdf)
